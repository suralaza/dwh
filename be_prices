from airflow import DAG
from airflow.decorators import task
from airflow.providers.postgres.hooks.postgres import PostgresHook
from airflow.utils.dates import days_ago
from airflow.operators.empty import EmptyOperator
from datetime import datetime, timedelta
from typing import List
import json
import os

API_URL = "http://msk-cpsba-app.alrosa.ru:10013/api/PriceCalculations/CalcPriceByValues"
API_HEADERS = {"accept": "application/json", "Content-Type": "application/json"}
GP_CONN_ID = "greenplum_cloud"

batch_fetch_size = 10000
default_args = {
    "owner": "airflow",
    "depends_on_past": False,
    "email_on_failure": False,
    "retries": 1,
    "retry_delay": timedelta(minutes=5),
}

with DAG(
    dag_id="load_stone_price_by_months",
    default_args=default_args,
    start_date=days_ago(1),
    schedule_interval=None,
    catchup=False,
    max_active_runs=1,
) as dag:

    start = EmptyOperator(task_id="start")
    end = EmptyOperator(task_id="end")

    @task
    def list_months() -> List[dict]:
        """
        Формирует список периодов (месяц_from, month_to) на основе данных в source_table.
        Возвращает список словарей: [{"date_from": "2024-01-01", "date_to": "2024-02-01"}, ...]
        """
        pg = PostgresHook(postgres_conn_id=GP_CONN_ID)
        conn = pg.get_conn()
        cur = conn.cursor()
        sql = """
        SELECT DISTINCT date_trunc('month', create_date) as month_start
        FROM source_table
        ORDER BY month_start
        """
        cur.execute(sql)
        rows = cur.fetchall()
        cur.close()
        conn.close()

        periods = []
        for r in rows:
            month_start = r[0]
            month_end = (month_start + timedelta(days=32)).replace(day=1)
            periods.append({
                "date_from": month_start.date().isoformat(),
                "date_to": month_end.date().isoformat()
            })
        return periods

    @task
    def dump_source_to_file_period(period: dict) -> str:
        """
        Дамп исходных строк для одного месяца в /tmp/stone_src_{YYYY_MM}.jsonl
        """
        date_from = period.get("date_from")
        date_to = period.get("date_to")
        out_path = f"/tmp/stone_src_{date_from.replace('-','_')}.jsonl"
        try:
            os.remove(out_path)
        except FileNotFoundError:
            pass

        pg = PostgresHook(postgres_conn_id=GP_CONN_ID)
        conn = pg.get_conn()
        cur = conn.cursor(name="src_cursor")

        sql = """
        SELECT product_id, create_date, weight, isBlackInclusions, isBGM,
               quantityOfStones, color, qual, form, qualityGroup, fluor,cavity, symmetryOut, polishOut, cutOut, hasCertificate
        FROM source_table
        WHERE (%s IS NULL OR create_date >= %s)
          AND (%s IS NULL OR create_date < %s)
        ORDER BY create_date
        """
        cur.execute(sql, (date_from, date_from, date_to, date_to))

        with open(out_path, "w", encoding="utf-8") as fout:
            while True:
                rows = cur.fetchmany(batch_fetch_size)
                if not rows:
                    break
                for r in rows:
                    payload = {
                        "priceListTypes": ["UPPInner", "UPPOuter", "UPPMin", "RAP"],
                        "date": datetime.utcnow().isoformat() + "Z",
                        "weight": float(r[2]) if r[2] is not None else None,
                        "isBlackInclusions": bool(r[3]),
                        "isBGM": bool(r[4]),
                        "quantityOfStones": int(r[5]) if r[5] is not None else 1,
                        "color": r[6],
                        "qual": r[7],
                        "form": r[8],
                        "qualityGroup": r[9],
                        "fluor": r[10],
                        "cavity": r[11],
                        "symmetryOut": r[12],
                        "polishOut": r[13],
                        "cutOut": r[14],
                        "hasCertificate": bool(r[15]),
                    }
                    rec = {
                        "product_id": r[0],
                        "create_date": r[1].isoformat() if r[1] else None,
                        "payload": payload
                    }
                    fout.write(json.dumps(rec, ensure_ascii=False) + "\n")
        cur.close()
        conn.close()
        return out_path

    # Здесь можно добавить таск, который выполняет запросы к API и вставки в БД для каждого файла.
    @task
    def process_file(path: str) -> dict:
        """
        Обработка подготовленного файла (асинхронные запросы к API + вставка в БД).
        Возвращает краткий результат.
        """
        # Реализуйте вашу логику асинхронных запросов и вставки.
        # Для примера возвращаем только путь и статус.
        return {"path": path, "status": "ok"}

    periods = list_months()

    # Task Mapping: создаёт отдельный экземпляр для каждого периода
    dumped = dump_source_to_file_period.expand(period=periods)
    processed = process_file.expand(path=dumped)

    start >> periods >> dumped >> processed >> end
